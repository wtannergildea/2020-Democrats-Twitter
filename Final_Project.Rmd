---
title: "Final Project"
author: "Tanner Gildea"
date: "4/2/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(twitteR)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(lubridate)
library(ggthemes)
library(shiny)
library(shinythemes)
library(tidytext)
```

```{r download}

# Access keys from developer app. 
consumer_key <- "JiBgIY3c2oSYaluzC9901ZpGH"
consumer_secret <- "T0cbKHAWJe6NW3e24F8KvvFeV6lv54aeNmavAGFyL9qHVFm7tL"
access_token <- "1091061777935355905-pd7WDjnoiOSxcEKMgxyucfOLHtOhk4"
access_secret <- "nLgDpWG4FhhbAvTGLeEET1nXkAkbVmMw08uZEmin54sRS"

# This section will actually conduct the download.

setup_twitter_oauth(
    consumer_key, consumer_secret, access_token, access_secret)

harris <- userTimeline("KamalaHarris", n = 3200, includeRts=F)
sanders <- userTimeline("BernieSanders", n = 3200, includeRts=F)
booker <- userTimeline("CoryBooker", n = 3200, includeRts=F)
buttigieg <- userTimeline("PeteButtigieg", n = 3200, includeRts=F)
castro <- userTimeline("JulianCastro", n = 3200, includeRts=F)
beto <- userTimeline("BetoORourke", n = 3200, includeRts=F)
warren <- userTimeline("ewarren", n = 3200, includeRts=F)
klobuchar <- userTimeline("amyklobuchar", n = 3200, includeRts=F)
inslee <- userTimeline("JayInslee", n = 3200, includeRts=F)
hickenlooper <- userTimeline("hickenlooper", n = 3200, includeRts=F)
gillibrand <- userTimeline("SenGillibrand", n = 3200, includeRts=F)
biden <- userTimeline("JoeBiden", n = 3200, includeRts=F)

```

```{r clean}

# To change from a list into a dataframe.
df.harris <- twListToDF(harris)
df.sanders <- twListToDF(sanders)
df.booker <- twListToDF(booker)
df.buttigieg <- twListToDF(buttigieg)
df.castro <- twListToDF(castro)
df.beto <- twListToDF(beto)
df.warren <- twListToDF(warren)
df.klobuchar <- twListToDF(klobuchar)
df.inslee <- twListToDF(inslee)
df.hickenlooper <- twListToDF(hickenlooper)
df.gillibrand <- twListToDF(gillibrand)
df.biden <- twListToDF(biden)
```

```{r}

# This will select only the metrics we care about in 2019, in addition to ignoring retweets.

tweets <- bind_rows(
  df.harris %>% filter(isRetweet==F) %>%
  select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),

df.sanders %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),

df.booker %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),
  
df.buttigieg %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),
  
df.castro %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),
  
df.beto %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),
  
df.warren %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),

df.klobuchar %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),

df.inslee %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),

df.hickenlooper %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),
  
df.gillibrand %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019),

df.biden %>% filter(isRetweet==F) %>%
    select(
      text, screenName, created, retweetCount, favoriteCount) %>% 
  filter(year(created) == 2019))
```

```{r}

```
# The Data

My plan is to conduct a number of analyses (text sentiment, basic stats, etc) on the Twitter data of current 2020 Democratic primary challengers. To make the project more managable, I will limit my timeline to start at the beginning of 2019.

I created a developer account on Twitter and was able to access its API. Using the twitteR package, I am able to download the text of the tweets from each candidate's personal account, in addition to other data such as their favorite and retweet activity. The data is relatively clean and tidy as is, although I filtered to remove retweets and some other information. In the future, I may include lat/long data to analyze other geographic trends, or see who they interact with the most on Twitter.

Here is the instructive guide I referenced for accessing, downloading, and manipulating the Twitter data using the twitteR package: https://medium.com/the-artificial-impostor/analyzing-tweets-with-r-92ff2ef990c6

# Summary Stats

A first visualization is each candidate's tweet activity over time. Specifically, I visualize tweet frequency
since January. I also want to create a table of summary stats for each candidate, including total number of tweets, average length of tweets in characters, average number of favorites, and average number of retweets.

```{r}

# Visualization

ggplot(tweets, aes(x = created, fill = screenName)) +
  geom_histogram(
    position = "identity", bins = 50, show.legend = FALSE) +
  facet_wrap(~ screenName, nrow = 2) +
  
  labs(title = "2020 Democratic Challengers' Tweet Activity",
       subtitle = "Frequency of Tweets in 2019",
       caption = "Source: Twitter") +
  xlab("Date") +
  ylab("Frequency") +
  theme_fivethirtyeight()
```

```{r}
# SUMMARY STATS

# Total number of tweets since January  1, 2019.

tweet_count <- tweets %>% 
  group_by(screenName) %>% 
  count()

# Average length of tweets in characters
mean_tweet_length <- tweets %>% 
  group_by(screenName) %>% 
  select(screenName, text) %>% 
  mutate(tweet_length = str_length(text)) %>% 
  summarize(mean_tweet_length = mean(tweet_length))

# Average number of favorites per tweet

fav_average <- tweets %>% 
  group_by(screenName) %>% 
  select(screenName, favoriteCount) %>% 
  summarize(fav_average = mean(favoriteCount))

# Average number of retweets per tweet

retweet_average <- tweets %>% 
  group_by(screenName) %>% 
  select(screenName, retweetCount) %>% 
  summarize(rt_average = mean(retweetCount))
```

I also want to create a tab that looks at specific word frequencies, with a search box and a bar chart with each candidate's total.

```{r frequencies}

# Word Use Frequency Table

word_frequency <- tweets %>% 
  group_by(screenName) %>% 
  unnest_tokens(word, text) %>% 
  count(word) 

# make table
```

I would like a drop down menu with candidate names, and if selected, a wordcloud of their most frequently used words.
```{r}


```

I also want a drop down menu of key issue words, and once selected, a visualization of how each candidate has used that word. 
```{r}

```


# Sentiment Analysis

One tab will be dedicated to sentiment analysis. Again, this will be used to differentiate candidates based on positivity, negativity, and possibly other factors.

```{r}
# bing and nrc lexicons are two different baskets of words for positivity/negativity 
bing_tweets <- tweets %>%
  unnest_tokens(word, text) %>%
  inner_join(get_sentiments("bing")) %>%
  group_by(screenName, sentiment) %>%
  tally() 

nrc_tweets <- tweets %>%
  unnest_tokens(word, text) %>%
  inner_join(get_sentiments("nrc")) %>%
  filter(sentiment == "positive" | sentiment == "negative") %>%
  group_by(screenName, sentiment) %>%
  tally() 

# you can also apply a numeric value to each word's positivity with the afinn lexicon
afinn_tweets <- tweets %>%
  unnest_tokens(word, text) %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(screenName) %>%
  summarize(average_positivity = mean(score))
```
